import csv
import io
import json
from datetime import datetime, timedelta

import requests
from plugins.bugs import BugsChartPeriod, BugsChartType, ChartData
from plugins.get_artist_data import get_artist_genre, search_artist_id
from scripts.get_access_token import get_token

from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from airflow.providers.amazon.aws.hooks.s3 import S3Hook

# ë‚ ì§œ ì„¤ì •
TODAY = datetime.now().strftime("%Y-%m-%d")


S3_BUCKET = "de5-s4tify"
S3_CSV_KEY = f"raw_data/bugs_chart_data/bugs_chart_{TODAY}.csv"
LOCAL_FILE_PATH = f"/opt/airflow/data/bugs_chart_with_genre_{TODAY}.csv"


# 1. Bugs ì°¨íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë° JSON ë³€í™˜
def fetch_bugs_chart():
    chart = ChartData(
        chartType=BugsChartType.All,
        chartPeriod=BugsChartPeriod.Realtime,
        fetch=True)
    chart_data = {"date": chart.date.strftime(
        "%Y-%m-%d %H:%M:%S"), "entries": []}
    for entry in chart.entries:
        print(f"ğŸ“Š ì°¨íŠ¸ ë°ì´í„° ì²˜ë¦¬: {entry.rank}. {entry.title} - {entry.artist}")

        artist_id = search_artist_id(entry.artist)
        genre = get_artist_genre(artist_id)

        chart_data["entries"].append(
            {
                "rank": entry.rank,
                "title": entry.title,
                "artist": entry.artist,
                "lastPos": entry.lastPos,
                "peakPos": entry.peakPos, 
                "image": entry.image,
                "genres": genre.split(", ") if genre else [],  # âœ… ë¦¬ìŠ¤íŠ¸ ë³€í™˜,
            }
        )
    return chart_data


# 2. JSON â†’ CSV ë³€í™˜ (genreë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥)
def convert_json_to_csv(**kwargs):
    ti = kwargs["ti"]
    data = ti.xcom_pull(task_ids="fetch_bugs_chart")

    output = io.StringIO()
    writer = csv.writer(
        output, quoting=csv.QUOTE_ALL
    )  # âœ… ëª¨ë“  í•„ë“œë¥¼ ìë™ìœ¼ë¡œ ë”°ì˜´í‘œ ì²˜ë¦¬

    # í—¤ë” ì¶”ê°€
    writer.writerow(["rank", "title", "artist", "lastPos",
                    "peakPos", "image", "genre", "date"])

    # ë°ì´í„° ì¶”ê°€
    for entry in data["entries"]:
        # ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì €ì¥
        genres = entry["genres"]

        # CSVì— ì¶”ê°€
        writer.writerow(
            [
                entry["rank"],
                entry["title"],
                entry["artist"],
                entry["lastPos"],
                entry["peakPos"],
                entry["image"],
                genres,  # ìˆ˜ì •ëœ ë¶€ë¶„: ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì €ì¥
                TODAY,
            ]
        )

    return output.getvalue()


# 3. ë¡œì»¬ì— CSV ì €ì¥ (í…ŒìŠ¤íŠ¸ìš©, ì‚­ì œ ìš©ì´í•˜ë„ë¡ ë³„ë„ í•¨ìˆ˜)
def save_csv_locally(csv_string):
    with open(LOCAL_FILE_PATH, "w", encoding="utf-8") as f:
        f.write(csv_string)


# 4. AWS S3 ì—…ë¡œë“œ
def upload_to_s3(**kwargs):
    ti = kwargs["ti"]
    csv_string = ti.xcom_pull(task_ids="convert_json_to_csv")
    save_csv_locally(csv_string)  # í…ŒìŠ¤íŠ¸ìš© ë¡œì»¬ ì €ì¥
    s3_hook = S3Hook(aws_conn_id="S4tify_S3")
    s3_hook.load_string(
        csv_string,
        key=S3_CSV_KEY,
        bucket_name=S3_BUCKET,
        replace=True)
    print(f"âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ: {S3_CSV_KEY}")


# DAG ì„¤ì •
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "start_date": datetime(2025, 2, 27),
    "retries": 1,
    "retry_delay": timedelta(minutes=2),
}

with DAG(
    "bugs_chart_dag",
    default_args=default_args,
    schedule_interval="10 0 * * *",  # ë§¤ì¼ 00:10 ì‹¤í–‰
    catchup=True,
) as dag:

    get_spotify_token_task = PythonOperator(
        task_id="get_spotify_token",
        python_callable=get_token,  # âœ… ë¨¼ì € ì‹¤í–‰í•´ì„œ Variable ê°±ì‹ 
        provide_context=True,
    )

    fetch_bugs_chart_task = PythonOperator(
        task_id="fetch_bugs_chart",
        python_callable=fetch_bugs_chart,
        provide_context=True,
    )

    convert_json_to_csv_task = PythonOperator(
        task_id="convert_json_to_csv",
        python_callable=convert_json_to_csv,
        provide_context=True,
    )

    upload_s3_task = PythonOperator(
        task_id="upload_to_s3",
        python_callable=upload_to_s3,
        provide_context=True,
    )

    (
        get_spotify_token_task
        >> fetch_bugs_chart_task
        >> convert_json_to_csv_task
        >> upload_s3_task
    )
